{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asma-10/GAN-Basic-Models/blob/main/LlamaIndex_RAG_Hugging_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install necessary dependencies\n",
        "!pip install llama-index llama-index-core llama-index-llms-ollama llama-index-embeddings-huggingface langchain llama-index-llms-huggingface llama-index-retrievers-bm25"
      ],
      "metadata": {
        "id": "8IrR7JDJ2Oql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload different data type"
      ],
      "metadata": {
        "id": "5xxT9z4ot9h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pptx and docx readers\n",
        "!pip install torch transformers python-pptx Pillow docx2txt"
      ],
      "metadata": {
        "id": "XnsKq_q_dy6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8Ob56TpzQXGo",
        "outputId": "d9c0b5b8-26db-4b1d-b6c5-a86de555a952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.llms.ollama import Ollama\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# uploading data : PDF, txt, pptx, docx, HTML documents, xlsx\n",
        "# it does read xlsx but does not analize it, this operation will be done with a retriever\n",
        "documents = SimpleDirectoryReader('data').load_data()"
      ],
      "metadata": {
        "id": "SBveYOUxn6nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ad2347-f9d3-404c-db87-11b4cf709c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load file /content/data/job_type.csv with error: 'utf-8' codec can't decode byte 0xe9 in position 73: invalid continuation byte. Skipping...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to use the right LLM and embed model\n",
        "Settings.llm = HuggingFaceInferenceAPI(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", api_key='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')\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")"
      ],
      "metadata": {
        "id": "PVm9oys__Gf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "D0DcTKLBg2Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "#from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "# index = VectorStoreIndex.from_documents(documents)\n",
        "# vector_retriever = index.as_retriever(similarity_top_k=5)\n",
        "# retriever = VectorIndexRetriever(index, top_k=3)\n",
        "# bm25_retriever = BM25Retriever.from_defaults(index=index, similarity_top_k=10)\n",
        "# add a reranker\n"
      ],
      "metadata": {
        "id": "CAvJJpYDUKGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reranker"
      ],
      "metadata": {
        "id": "kOxDn48WebVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-postprocessor-sbert-rerank"
      ],
      "metadata": {
        "id": "wUH2tYAHedrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
        "\n",
        "rerank = SentenceTransformerRerank(\n",
        "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", top_n=3\n",
        ")"
      ],
      "metadata": {
        "id": "drpqw6QajiBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=10, node_postprocessors=[rerank]\n",
        ")"
      ],
      "metadata": {
        "id": "ur5YN383ednv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\n",
        "    \"whos is the manager of external relations and sponsoring ?\"\n",
        ")\n",
        "# print(response) for a simple display\n",
        "\n",
        "# display final response\n",
        "from llama_index.core.response.notebook_utils import display_response\n",
        "\n",
        "display_response(response)"
      ],
      "metadata": {
        "id": "VsL-6Fjblxql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## end rerank test"
      ],
      "metadata": {
        "id": "Tab9Cx0_kNf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a retriever\n",
        "# set a router to pick between different query engines\n",
        "# vector_retriever = index.as_retriever(similarity_top_k=10)\n",
        "# Set a retriever for different doc types\n",
        "# example of a full query engine\n",
        "llm = HuggingFaceInferenceAPI(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", api_key='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')\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "bm25_retriever = BM25Retriever.from_defaults(index=index, similarity_top_k=10)\n",
        "query_engine = RetrieverQueryEngine.from_args(\n",
        "    retriever=bm25_retriever,\n",
        "    llm=llm,\n",
        ")\n"
      ],
      "metadata": {
        "id": "S1zZcDyIZGCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\n",
        "    \"whos is the manager of external relations and sponsoring ?\"\n",
        ")\n",
        "# print(response) for a simple display\n",
        "\n",
        "# display final response\n",
        "from llama_index.core.response.notebook_utils import display_response\n",
        "\n",
        "display_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "ltyWcf59R6X2",
        "outputId": "af5ca5a9-3d7b-45a1-d0ee-dce6d842b5cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**`Final Response:`** BOUROUBA Asma is the manager of external relations and marketing."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End test"
      ],
      "metadata": {
        "id": "4TgKKUCxg8mI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the LLM and the embed_model"
      ],
      "metadata": {
        "id": "CO6zQ-pPYpzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "store index, instanciate the query_engine , ask the engine"
      ],
      "metadata": {
        "id": "S_CbQv4WYuLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# Add a prompt template\n",
        "\n"
      ],
      "metadata": {
        "id": "juKFYnF5I1i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"what are the attributs of that xlsx file?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "_7nMQ95ScS1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qOawIslYkLG_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}